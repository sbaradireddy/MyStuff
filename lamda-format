import msal
import requests
import boto3
import base64
import io, os

def lambda_handler(event, context):
    
    
    scopes = ['https://graph.microsoft.com/.default']

# Azure AD App details
CLIENT_ID = xfbdzn
CLIENT_SECRET = sffrbhdxgn
TENANT_ID = afgsagv

# AWS s3 bucket details
S3_BUCKET = "pr-home-datascience"

# Set up MSAL
authority = f'https://login.microsoftonline.com/{TENANT_ID}'
#authority = f'https://login.microsoftonline.com/common/{TENANT_ID}'
app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)


# Authenticate and get token
result = app.acquire_token_for_client(scopes=scopes)
access_token = result['access_token']

graph_url = 'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/mailFolders/inbox/messages?$filter=hasAttachments eq true'

headers = {
    'Authorization': f'Bearer {access_token}','Accept': 'application/json'
}
s3 = boto3.client('s3')

# Retrieve emails
response = requests.get(graph_url, headers=headers)
emails_with_attachments = response.json().get('value', [])

#print(emails_with_attachments)
for email in emails_with_attachments:
    email_id = email['id']
    folder_name = email_id.split('-')[2].rstrip('/')+'/'
    try:
        response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=folder_name, Delimiter='/')
        if 'Contents' in response or 'CommonPrefixes' in response:
            print('Email already exists in bucket')
            continue
        else:
            s3.put_object(Bucket=S3_BUCKET, Key=folder_name)
            print(f"Folder {folder_name} created in Bucket")
            email_content = email['subject'] + email['body']['content']
            # create a txt file with email subject and body
            filename = 'body.HTML'
           
            with open(filename, 'w') as file:
                file.write(email_content)
            s3_key = f"{folder_name}{filename}"
            s3.upload_file(filename, S3_BUCKET, s3_key)
            print(f"Uploaded email content as {filename} to S3")
    except Exception as e:
        print('An error occured', e)
    
    attachments_url = f'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/messages/{email_id}/attachments'
    response1 = requests.get(attachments_url, headers=headers)
    attachments = response1.json().get('value', [])
    for attachment in attachments:
        if '@odata.type' in attachment and attachment['@odata.type'] == '#microsoft.graph.fileAttachment':
            attachment_content = attachment['contentBytes']
            attachment_name = attachment['name']
            s3_key = f"{folder_name}{attachment_name}"
            with open(attachment_name, 'wb') as f:
                f.write(attachment_content.encode('utf-8'))

            # Upload to S3
            with open(attachment_name, 'rb') as f:
                s3.upload_fileobj(f, S3_BUCKET, s3_key)
            print(f"Uploaded {attachment_name} to S3")
            
    
######
import msal
import requests
import boto3
import base64
import io, os

def lambda_handler(event, context):
    scopes = ['https://graph.microsoft.com/.default']

    # Azure AD App details
    CLIENT_ID = 'xfbdzn'
    CLIENT_SECRET = 'sffrbhdxgn'
    TENANT_ID = 'afgsagv'

    # AWS S3 bucket details
    S3_BUCKET = "pr-home-datascience"

    # Set up MSAL
    authority = f'https://login.microsoftonline.com/{TENANT_ID}'
    app = msal.ConfidentialClientApplication(CLIENT_ID, authority=authority, client_credential=CLIENT_SECRET)

    # Authenticate and get token
    result = app.acquire_token_for_client(scopes=scopes)
    access_token = result['access_token']

    graph_url = 'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/mailFolders/inbox/messages?$filter=hasAttachments eq true'

    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json'
    }
    
    s3 = boto3.client('s3')

    # Retrieve emails
    response = requests.get(graph_url, headers=headers)
    emails_with_attachments = response.json().get('value', [])

    for email in emails_with_attachments:
        email_id = email['id']
        folder_name = email_id.split('-')[2].rstrip('/') + '/'
        
        try:
            response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=folder_name, Delimiter='/')
            if 'Contents' in response or 'CommonPrefixes' in response:
                print('Email already exists in bucket')
                continue
            else:
                s3.put_object(Bucket=S3_BUCKET, Key=folder_name)
                print(f"Folder {folder_name} created in Bucket")
                
                email_content = email['subject'] + email['body']['content']
                
                # Create a txt file with email subject and body
                filename = 'body.HTML'
                with open(filename, 'w', encoding='utf-8') as file:
                    file.write(email_content)
                    
                s3_key = f"{folder_name}{filename}"
                s3.upload_file(filename, S3_BUCKET, s3_key)
                print(f"Uploaded email content as {filename} to S3")
        
        except Exception as e:
            print('An error occurred', e)
        
        # Fetch attachments
        attachments_url = f'https://graph.microsoft.com/v1.0/users/HomeDSAWS@plymouthrock.com/messages/{email_id}/attachments'
        response1 = requests.get(attachments_url, headers=headers)
        attachments = response1.json().get('value', [])
        
        for attachment in attachments:
            if '@odata.type' in attachment and attachment['@odata.type'] == '#microsoft.graph.fileAttachment':
                attachment_content = base64.b64decode(attachment['contentBytes'])
                attachment_name = attachment['name']
                s3_key = f"{folder_name}{attachment_name}"
                
                with open(attachment_name, 'wb') as f:
                    f.write(attachment_content)

                # Upload to S3
                with open(attachment_name, 'rb') as f:
                    s3.upload_fileobj(f, S3_BUCKET, s3_key)
                print(f"Uploaded {attachment_name} to S3")


#################################
Test Event Name
test

Response
{
  "errorMessage": "[Errno 30] Read-only file system: 'AWS EC2 Request Form.docx'",
  "errorType": "OSError",
  "requestId": "b29e2030-b2cd-41ab-93fc-7e78a736a68e",
  "stackTrace": [
    "  File \"/var/task/lambda_function.py\", line 75, in lambda_handler\n    with open(attachment_name, 'wb') as f:\n"
  ]
}

Function Logs
START RequestId: b29e2030-b2cd-41ab-93fc-7e78a736a68e Version: $LATEST
Folder y0ZBKcm7bAAAaObBdAAA=/ created in Bucket
An error occurred [Errno 30] Read-only file system: 'body.HTML'
LAMBDA_WARNING: Unhandled exception. The most likely cause is an issue in the function code. However, in rare cases, a Lambda runtime update can cause unexpected function behavior. For functions using managed runtimes, runtime updates can be triggered by a function change, or can be applied automatically. To determine if the runtime has been updated, check the runtime version in the INIT_START log entry. If this error correlates with a change in the runtime version, you may be able to mitigate this error by temporarily rolling back to the previous runtime version. For more information, see https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html
[ERROR] OSError: [Errno 30] Read-only file system: 'AWS EC2 Request Form.docx'
Traceback (most recent call last):
  File "/var/task/lambda_function.py", line 75, in lambda_handler
    with open(attachment_name, 'wb') as f:END RequestId: b29e2030-b2cd-41ab-93fc-7e78a736a68e
REPORT RequestId: b29e2030-b2cd-41ab-93fc-7e78a736a68e	Duration: 3916.48 ms	Billed Duration: 3917 ms	Memory Size: 128 MB	Max Memory Used: 86 MB	Init Duration: 348.60 ms

Request ID
b29e2030-b2cd-41ab-93fc-7e78a736a68e
        

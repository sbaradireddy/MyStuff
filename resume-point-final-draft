12+ years of Professional IT experience with Data warehousing and Business Intelligence background in Designing, Developing, Analysis, Implementation and post implementation support of DWBI applications. 
 Extensive experience on Data Engineering including Ingestion, Datalake, Datawarehouse, Reporting and Analytics. 
 Strong knowledge and experience on Data Analysis, Data Lineage, Big Data pipelines, Data quality, Data Reconciliation, Data transformation rules, Data integration and Data orchestration tools. 
 Solid Experience and understanding of Implementing large scale Data warehousing Programs and E2E Data Integration Solutions on Snowake Cloud, AWS Redshift, Informatica Intelligent Cloud Services (IICS - CDI) & Informatica PowerCenter integrated with multiple Relational databases (MySQL,Teradata, Oracle, Sybase, SQL server, DB2) 
 Knowledge and experience on AWS services like Redshift,Redshift spectrum,S3,Glue,Athena, Lambda,cloudwatch and EMRs like HIVE, Presto 
 Hands on Experience on Python programming for data processing and to handle Data integration between On-prem and Cloud DB or Datawarehouse.
  Experience with container based deployments using Docker, working with Docker images, Docker registries. 
 Hands-On experience on Analyzing SAS ETL, Implementation of Data integration in Informatica using XML, Webservices, SAP ABAP, SAP IDoc. 
 Experienced with Teradata utilities Fast Load, Multi Load, BTEQ scripting, Fast Export, SQL Assistant and Tuning of Teradata Queries using Explain plan 
 Worked on Dimensional Data modelling in Star and Snowake schemas and Slowly Changing Dimensions(SCD). 
 Developed Informatica Development Standards, Best practices, Solution Accelerators and Re-usable components for design and delivery assurance. 
 Pro-Active to Production Issues, punctuality in Meeting deadlines and always follow First Time Right (FTR) and On Time Delivery (OTD) approach. 


PROFESSIONAL EXPERIENCE Condential Snowake Data Engineer Responsibilities: 
AWS Data Engineer Responsibilities: 
 Worked on Architecture Design for Multistate implementation or deployment. Implement One time Data Migration of Multistate level data from SQL server to Snowake by using Python and SnowSQL.  Day to-day responsibility includes developing ETL Pipelines in and out of data warehouse, develop major regulatory and nancial reports using advanced SQL queries in snowake. 
 Stage the API or Kafka Data(in JSON le format) into Snowake DB by FLATTENing the same for dierent functional services. 
  Build Docker Images to run airow on local environment to test the Ingestion as well as ETL pipelines. Building/Maintaining Docker container clusters managed by Kubernetes. Utilization of Kubernetes and Docker for the runtime environment of the CI/CD system to build, test and deploy. 
  Created Airow DAGs to schedule the Ingestions, ETL jobs and various business reports. 
 Support Production Environment and debug issues using Splunk logs. On call support for production job failures and lead the eort on working with various teams to resolve the issues.
 

AWS Data Engineer Responsibilities: 
 AWS Data Engineer Responsibilities: Condential ETL Lead/ Sr.ETL Cloud Developer Responsibilities: Part of Architecture design to migrate current ETL jobs to Cloud using Attunity Replication,AWS Redshift and Snaplogic Framework . 
 Developed Business logic in semantic layer by creating views in AWS Redshift to provide transformation logic visibility. 
 Create and load staging tables based on the logic dened in views using Distribution, Sort Key’s for optimal performance. 
 Part of the team to design common snaplogic pipeline to load all tables by reading meta data dynamically based on each subject area 
 Collect Load Stats of Start Time, End Time, Total Records loaded and Notify production support team with load details 
 Perform complex transformations from dierent sources in AWS Redshift and Unload the result dataset into HIVE/Presto stage which is built on AWS Data lake S3.
  Builds the HIVE query with set of Applicable Parameters to load the data from HIVE/Presto Stage to Actual HIVE/Presto Target table which is again built on AWS S3 path. In Some cases, Unload of data from Stage to Target table happens through AWS RDS. 
 Perform tuning of AWS Redshift SQL Queries by eectively using Appropriate Distribution Styles and Keys. 
 Build Python Programming to extract data from AWS S3 and load into SQL server for one of business teams as they are not exposed to cloud. 
 Creation of Business views using DENODO VDP(Virtual DataPort) and scheduling jobs using Active Batch scheduler. 
 Design and Develop ETL Processes in AWS Glue to migrate Campaign data from external sources like S3, Parquet/Text Files into AWS Redshift.
  Used AWS glue catalog with crawler to get the data from S3 and perform sql query operations using AWS Athena 
  Create external tables with partitions using AWS Athena and Redshift 
 Create a Lambda function to run the AWS Glue job based on the de ned AWS S3 event 
 Created monitors, alarms, notications and logs for Lambda functions, Glue Jobs using Cloudwatch.  ETL Lead/ Sr. ETL Developer Responsibilities: 
Condential ETL Lead/ Sr. ETL Developer Responsibilities: 
 Analysed SAS ETL and Implemented the ETL logic as Informatica mappings. Eectively using IICS Data integration console to create mapping to consolidate and bring data into MedeAnalytics system from dierent source systems like Sql Server, Oracle, Flat Files. 
  Develop reusable & concurrent executable workows in IICS for SAS data extraction 
 Involved in performance optimization of IICS jobs and design ecient queries to query data. Architect the ETL process for Migration of data from Datamart Analytix system to the Teradata Environment 
  Worked on Performance constraints of the jobs using Multi Load and partition concept 
 Handled history load of 5 yrs of weekly and monthly data. 
 Created Teradata views with required Grant roles and user groups for dierent authorization level 
 Created BTEQ Scripts for pre population of the work tables prior to the main load process. Used SQL Query optimization (explains plans, collect statistics, data distribution across AMPS, primary and secondary indexes, locking, etc.) to achieve better performance. 
  Work with business owners in understanding the business requirements. 
 Preparing estimations for all development and enhancement work. 
 Analyze and solve business problems at their root, stepping back to understand the broader context.  Functional testing of the developed objects. 
 Performance tuning of Informatica Mappings & Pl/Sql. 
 Leading and developing a team of DWBI Engineers. Creating all functional and non-functional requirements along with High level and Low-Level Design documents 
  Establishing ETL Governance standards and best practices. Solution based architecture for ETL problems, unit testing strategies and development of ETL jobs for data warehouses. 



###############################MLOPS############
 Machine Learning Support Mlops, LeaD TECHNICAL SKILLS PROFESSIONAL EXPERIENCE Condential Machine Learning Support (MLOps) Lead Responsibilities: We provide IT Staff Augmentation Services! 
 Data Science Model Life Cycle 
 ML Model Performance Tuning (with SME inputs) 
 ML Model Deployment & Monitorin 
 Docker Containers, Kubernetes & ML Pipelines 
 Model Deployment & Monitoring in Cloud (MLOps) 
 (Azure ML Service/ AWS Sage Maker/ Google AI Platform, IBM) 
 Actual Project Experience in at least one Cloud based ML environment 
 Azure ML Service & Python SDK  Python 3.x Programming 
 RESTful APIs for wrapping ML Models / System Integration 
 CI/CD Integration  Gain understanding of Pilot Scope ML models and methodology used.
  Design and Build the Model Deployment and Monitoring solution for Pilot scope 
 Design and Build production ML pipelines if not available 
 Design and Build deployment and monitoring scripts to be developed 
 Design and Build Model Monitoring scripts & dashboards Regular interaction with business for nalizing the requirements, and model monitoring metrics, reviewing implementation plan etc. 
  Perform Model Deployment in production environment (Azure) 
 Perform Model Refresh 
 Monitor Model Performance 
 Perform Model tuning 
 Tune monitoring scripts and reporting dashboards 
Analyze and Dene Updates to ML Pipeline, Deployment & Monitoring scripts to accommodate any application/data/model changes 
  Model Version & Conguration Management 


Senior AWS mlops Engineer Resume 
 SUMMARY 
 Experience inLinuxAdministration Installation, Conguration, Tuning and Upgrades of Linux. Worked on cloud-based servers likeAWS,AZURE. 
  Implemented cloud servicesIAAS, PAAS, andSaaSwhich includeOpenStack,DockerandOpenShift. Highly experienced in AWS Cloud platform and its features which includes EC2, VPC, EBS, AMI, SNS, RDS, Cloud Watch, Cloud Trail, Cloud Formation AWS Cong, Autoscaling, Cloud Front, IAM, S3, and R53. 
 Administration and Architect of public and private cloud platforms AWS. Experienced in Amazon EC2 setting up instances, virtual private cloud (VPCs), and security groups. Setting up databases in AWS using RDS, storage using S3 bucket, and conguring instance backups to S3 bucket. 
 Installed, congured, and maintained DNS systems using BIND, Route53 (AWS), and Power DNS. Designing and distribution of data across all teh nodes and Clusters on dierent availability zones in AWS Redshift. 
 DevOps experience with Puppet, Maven, Git, Jenkins, and AWS, Azure. Experience in Installing, upgrading, and conguring Redhat Linux 4.x, 5.x and 6.x using Kickstart Servers and Interactive Installation.
  Experience in Troubleshooting of all aspects of teh Red Hat Linux operating environments. Experienced in Administration of Production, Development and Test environment carrying Windows, Ubuntu, Red Hat Linux, CentOS, and SUSE Linux. 
 Build teh applications using Maven and Jenkins Continues Integration Tools. Experience in Creation and managing user accounts, security, rights, disk space, quotas and process monitoring in Redhat Linux. 
 Used Terraform modules for two tier Architecture which includes AWS resources VPC, Subnets, Security groups, Ec2, Load Balancers, Auto scaling group, Cloud watch Alarms, ECS clusters, S3 buckets for logs. 
  Installation and upgradation of Packages and Patches conguration management, version control. Have experience in phases of software development life cycle including project management, functional requirements denition, technical design, development, testing, quality assurance. Estimated storage requirements for applications and administration. 
TECHNICAL SKILLS Cloud Platform: 
AWS, Azure and GCP Tracking Tools: JIRA, Remedy and Service now Build Tools: Ant, Maven, Gradle. Containerization and orchestration: Docker, Docker Swarm, EKS, Kubernetes Clusters, AWS ECS. Application Servers: JBoss, Apache Tomcat, Nginx, Web logic Continuous Integration tools: Jenkins, Bamboo, Git lab CI, TeamCity Conguration Management: Chef, Puppet, Ansible Experience in working with ITIL Methodologies, Agile/SCRUM based product development teams. Experience in writing Bash shell scripts to automate teh administrative tasks and management using cron and at jobs. 

 TEMPHas experience in 24*7 Production Support and in mentoring junior developers. Experience in using tools like Jira and OTRS for ticketing. 
 Hands on experience in using monitoring tools like Nagios. Integrated additional Docker Slave Nodes for CI/CD (Jenkins) using custom Docker Images and Worked on all major components of Docker like Docker Daemon, Hub, Images, Registry, Swarm etc. 
 Extensive experience using MAVEN and ANT as build management tools for building of deployable artifacts from source code. 
 Used Jenkins pipelines to drive all micro services builds out to teh Docker registry and tan deployed to Kubernetes, created Pods and managed using Kubernetes. 
 Responsible for implementing containerized based applications by usingAzure Kubernetes Service (AKS). 
 Developed microservice on boarding tools leveraging Python and Jenkins allowing for easy creation and maintenance of build jobs and Kubernetes deploy and services. 
  Refactoring of monolithic applications to aMicroservicesand Component based architectures. Worked on deployment automation of all teh micro services to pull image from teh private docker registry and deploy to docker swarm cluster using Ansible. 
  CreatingAnsible Playbooks, to Deploy VM and install teh Components as per requirements. 
 Worked with OpenShift platform in managing Docker containers and Kubernetes Clusters. Experienced in Branching, Tagging, and maintaining teh versions across dierent SCM tools like GitHub, Subversion (SVN) on Linux and Windows platforms. 
 Experience in setting up Baselines, Branching, Merging and Automation Processes using Shell, Perl, Ruby, Python and Bash Scripts. Hands on experience in packaging teh les and place them in Artifactory such as Nexus, JFrog and SonarQube. 
 Hands on experience on Chef Enterprise. Installed workstation, bootstrapped nodes, wrote recipes and cookbooks and uploaded them to chef server. 
 Managed On-site OS/Applications/Services/Packages using Chef as well as AWS for EC2/S3/Route53 and ELB with Chef Cookbooks. 
Web Technologies: HTML, JavaScript, CSS, XML, and JSON Operating Systems: RHEL/CentOS 5.x/6.x/7, Ubuntu/Debian/Fedora, Sun Solaris 7/8/9/10, Windows Server 2003/2008/201 Scripting Languages: Shell, Bash, Perl, Ruby, Groovy and Python scripting Databases: MySQL, MongoDB, Cassandra, Oracle, PostgreSQL, SQL Server Infrastructure Spin-ups Tools: Terraform, AWS cloud formation, Azure ARM 

PROFESSIONAL EXPERIENCE 
 Conguring Azure web apps, Azure App services, Azure Application insights, Azure Application gateway, Azure DNS, Azure Trac manager, Azure Network Watcher, Azure storage, Azure Active Directory, and Azure Resource Manager (ARM). 
 Implemented Azure Media and Content delivery, Azure Networking, Azure Hybrid integration, Azure Identity, and Access Management, Azure Data Factory and Storage, Azure compute services, and Azure Web apps. 
 Managed Azure Infrastructure Azure Web Roles, Worker Roles, VM Role, Azure SQL, Azure Storage, Azure AD Licenses, Virtual Machine Backup and Recover from a Recovery Services Vault using Azure PowerShell and Azure Portal. 
 Created Azure Site Recovery and Azure Backup- Deployed Instances on Azure environments and in Data centers and migrating to Azure using Azure Site Recovery and collecting data from all Azure Resources using Log Analytics and analyzed teh data to resolve issues. 
 Deployed Azure IaaS virtual machines (VMs) and Cloud services (PaaS role instances) into secure VNets and subnets managed and optimize teh CI (Continuous Integration) tools like Azure DevOps. 
 Automated build and release process (CI/CD) using Azure DevOps services and to create test plans, to report bugs & to track defects. 
 Prepare data, train, deploy, and monitor machine learning models with Azure Pipelines. Monitoring deployed machine learning models (such as for performance or data-drift analysis) 
 Build reproducible workows and models by reducing variations in model iterations and provide fault tolerance for enterprise-grade scenarios through reproducible training and models. 
 Extend teh applications to IoT edge gateways and devices with Azure SQL Edge and supported modern cloud applications with Azure SQL Database. 
 Analyze and dene updates to ML pipelines, deployment and monitoring scripts to accommodate any application/data/model changes. Regular interactions with business for nalizing teh requirements and model monitoring metrics, reviewing implementation plans. 

 Terraform scripts to automate and deploy Azure cloud services and developed Terraform templates dat can spin up infrastructure for multi-tier application and provisioned boot strapped software on Cloud with Terraform. 
 Procient in using Ansible Tower, which provides an easy-to-use dashboard and role-based access control, so dat it is easier to allow individual teams access to use Ansible for their deployments. Integrated Jenkins CI/CD pipeline with various DevOps tools such as GIT, Nexus, SonarQube, Ansible. 
 Developed build and deployment scripts using ANT and MAVEN as build tools in Jenkins to move from one environment to other environments. 
 Worked on container-based deployments using Docker, working with Docker images, Docker Hub, Docker Compose, Docker-registries and Kubernetes. 
 Implementing a Continuous Delivery framework using Jenkins, Ansible, Maven & Nexus, Urban Code Deploy in Linux environment. 
 Have very strong expertise noledge and experience with PowerShell, Perl and Groovy scripting in automating many Jenkins, Urban Code Deploy activities with cloud foundry. 
 Worked with teh development team to deploy new libraries with Micro Services Architecture using REST APIs & Spring Boot. 
 Wrote Ansible Playbooks with Python SSH as teh Wrapper to Manage Congurations of Open stack Nodes and Test Playbooks on AWS instances using Python. Implemented a production ready, load balanced, highly available, fault tolerant Kubernetes infrastructure. Created private cloud using Kubernetes dat supports DEV, TEST, and PROD environments. 
 Integrated DynaTrace with teh Kubernetees Cluster to Automate detection of Kubernetes properties and annotations. 
 Leveraged Kubernetes labels in DynaTrace and imported labels and annotations where it detects all labels attached to pods at application deployment time. 
 Extensively Working on Docker service for our Docker images and worked with Docker container networks communications using Docker Weave rolling updates to implement zero downtime PROD deployments and worked with Docker Trusted Registry as repository. 
 Integrated additional Docker Slave Nodes for CI/CD (Jenkins) using custom Docker Images and Worked on all major components of Docker like Docker Daemon, Hub, Images, Registry, Swarm etc.  Congured & Managed Monitoring Tools such as Splunk, Nagios for Resource Monitoring/Network Monitoring/Log Trace Monitoring and Cloud Watch and ELK to monitor OS metrics, server health checks, le system usage etc. 
 Monitored servers, switches, and ports using Nagios Monitoring tool and assisted internal users of Splunk in designing and maintaining production quality dashboards. 
 DeployedPrometheuswithGrafanato monitor theKubernetescluster and congured alerts ring when dierent conditions met. 
 IntegratedEFK (Elasticsearch, Fluentd, Kibana)stack as teh logging solution for teh deployed Kubernetes cluster. Provided solution oncontainer runtimeby performing proof of concepts onCNCFruntimes. 
 Provided solutions on new technologies based on teh proof of concepts to deploy onKubernetescluster for edge/IOT environment. 
 Migrate data to/from Microsoft Azure Cloud Platform, Azure SQL DB, Hadoop data on teh Azure HDInsight Service using SSIS. 
  Designed and deployed custom JIRA Exporter for Prometheus to generate appropriate data points. Provided 24X7 support to production servers also to oshore team and systems and was involved in creating documentation.
  UsingAnsibleinventories to dene groups of hosts Exceptional Customer Service. CreatingAnsible playbooksto congure systems to a specied state 
 Creating and usingAnsible templatesto create customized conguration les for hosts and CreatingAnsibleroles UsingAnsibleVault in playbooks to protect sensitive data Administrative Support.  Installed and congured Blackduck/Checkmarx scanning tool in our CI/CD process for continuous scanning of artifacts once it is build. 
 Worked on AWS Cloud Formation templates to create custom sized VPC, subnets, EC2 instances, ELB, security groups. Worked on tagging standard for proper identication and ownership of EC2 instances and other AWS services like Cloud Front, CloudWatch, OpsWork, RDS, ELB, EBS, S3, glacier, Route53, SNS, SQS, KMS, Cloud Trail, and IAM. 
 Created complex infrastructure which consists of following services in AWS such as EC2 instances, EBS, Security groups, Subnet, VPC, S3 storage buckets, Elastic File Storage (EFS) systems, Elastic Load Balancers (ELB), Application load balancers, Auto scaling groups, High availability zones, Route53, IAM roles, AWS Lambda, AWS Elastic Beanstalk, AWS Cognito autantication to quickly deploy and manage teh applications Using Terraform. 
 Congured AWS Beanstalk for deploying and scaling web applications and services developed with Java, PHP, Node.js, Python and Docker on familiar servers such as Apache, and IIS. 
 DeployOpenstackenvironments through automated tools, Ansible / custom pipeline and Terraform for Infrastructure Automation 
 Wrote Ansible playbooks from scratch in YAML. Installing, setting up & Troubleshooting Ansible, created and automated platform environment setup. 
 Extensive used of Elastic Load Balancing mechanism with Auto Scaling feature to scale teh capacity of EC2 Instances across multiple availability zones in a region to distribute incoming high trac for teh application. 
 Orchestrated and migrated CI/CD processes using Cloud Formation, terraform templates and Containerized teh infrastructure using Docker setup in AWS and Amazon VPCs.
 Hands-on experience on supporting, optimizing and critical deployments in AWS Lambda, automating infrastructure, CI/CD and DevOps process. 
 Developed and implemented architectural solutions involving multiple Pivotal Cloud Foundry (PCF) foundations on VMware virtual infrastructure (on-premises). 
 Worked with developer to automate teh mobile application builds from teh scratch. Creating S3 buckets and restricting access to buckets and directories to specic IAM users. Automating conguration management, infrastructure and application deployments using Ansible. 
 Automated teh front-ends platform into highly scalable, consistent, repeatable infrastructure using high degree of automation using Ansible, Jenkins, and Cloud Formation. 
 Created multiple Jenkins and AWS DevOps CI/CD Pipelines for our Infrastructure code validation and verication 
 Controlling and Maintaining all modules within Ansible Module Library and use Visual Studio Team Service (VSTS) as source control for source code. 
 Making deployments of microservices as containers by using containerization tools like Docker and Docker Compose. Docker Swarm and Kubernetes for orchestration and MS Azure to ensure continuous deployments into teh dierent environments. 
 Developed build and deployment scripts using Gradle and Ant, Maven as build tools in Jenkins to move from one environment to other environments. 
 Jenkins is Built on Docker container and teh master controller Kubernetes controls pods. Designing and implementing Container orchestration systems with Docker Swarm and Kubernetes. 
 Experience in designing Kubernetes cluster using AWS-Kops (EKS) conguring and deploying teh Kubernetes dashboard to access teh cluster via its web-based user interface. Customize teh Halyard conguration to deploy Spinnaker in private Kubernetes cluster. Mirrored teh Docker images required for Spinnaker from external registry to private Docker. 
 Worked on creating pipeline to automate application deployment on Kubernetes using JenkinsDeployed and administered EKS clusters on AWS native services. 
 Used AWS EKS to run teh Kubernetes management infrastructure across multiple zones to eliminate a single point of failure and created alarms and trigger points in CloudWatch based on thresholds and monitored teh server’s performance, CPU Utilization, disk usage.
  Developed Ruby/Python scripts to monitor health of Mongo databases and perform ad-hoc backups using Mongo dump and Mongo restore. 
 Creation, conguration and monitoring Shards sets. Analysis of teh data to be shared, choosing a shard Key to distribute data evenly. Architecture and Capacity planning for MongoDB clusters. Implemented scripts for mongo DB import, export, dump and restore. 
 Worked on deployment automation of all microservices to pull image from Private Docker registry and deploy to Kubernetes cluster.Good understanding of OpenShift platform in managing Docker containers and Kubernetes Clusters. 
 Worked with Operations team on specic Ansible Playbooks used in Jenkins for application installations and related cong les to deploy teh packages in production NoSQL Databases. 
 DevOps Engineer Responsibilities: Experience in conguration of teh monitoring and alerting tools according to teh requirements like AWS Cloud Watch, Nagios, Splunk Enterprise, New Relic for VPN connections. 
 Built various containers using Docker engine and Docker Machine environments, to deploy teh micro services-oriented environments for scalable applications. 
 Wrote Ansible playbooks to setup Continuous Delivery pipeline and this primarily consists of a Jenkins and Sonar server, teh infrastructure to run these packages and various supporting software components such as Maven. 
 Administered Jenkins for Continuous Integration and deployment into Tomcat/Web Sphere/APACHE JBOSS Application Servers. 
 Implemented Elastic Search Ngnix Proxy Cleanup and in Re-Architecture process of ELK and Installing Universal Forwarders and Heavy Forwarders to bring any kind of data elds into Splunk and writing Splunk Queries, Expertise in searching, monitoring, analyzing and visualizing Splunk logs. 
 Writtengroovy scriptsto usemulti branch pipeline projects in Jenkinsto congure it as per client’s requirements and Wrote shell, Bash and python scripts for day to day administrative tasks. 
 Implemented AWS solutions using EC2, S3, RDS, EBS, Elastic Load Balancer, Auto scaling groups and designed teh data models to use in AWS Lambda applications which are aimed to do complex analysis creating analytical reports for end-to-end traceability and denition of Key Business elements from Aurora. 
 Provisioning of EC2 instances, built via Ansible, and integrated into local area oces in 4 time zones. Amazon RDS, VPC construction, Security Group policies, IAM, Route 53, Cloud Formation, S3, Glacier and OpsWorks. 
 Implemented AWS high availability using AWS Elastic Load Balancing (ELB), which performed balance across instances in multiple availability zones. 
 Congured and managed AWS Glacier to move old data to archives, based on retention policy of database/applications. 
 Assigned AWS elastic IP addresses to work around host or availability zone failures by quickly remapping teh address to another running instance. 
 Designed, congured, deployed Amazon Web Services for a multitude of applications utilizing teh amazon services focusing on high-availability, fault tolerance and Auto Scaling. 
 Integrated teh Amazon Kinesis with S3 bucket to store teh generated application data logs. Created AWS Route53 to route trac between dierent regions. 
 Implementing a Continuous Delivery framework using Jenkins, Maven in Linux environment. Created, developed and test environments of dierent applications by provisioning Kubernetes clusters on AWS using Docker, Ansible, and Terraform. 
 Virtualized teh servers using teh Docker for teh test environments and dev-environments needs and conguring automation using Docker containers. 
 Engineer Responsibilities: 
Experience in writing Docker les and deploying applications on containers and deployed Docker containers by using images stored in repository using Kubernetes, both on premise and on AWS cloud.  Deployed Kubernetes cluster on AWS using Kops with Multi-Master setup to increase teh availability, deployed Consul clusters for service discovery, weaver to perform teh subnetting between teh PODS. 
 Worked with Ansible playbooks for virtual and physical instance provisioning, conguration management, patching and software deployment. 
 Experience in working with GIT to store teh code and integrated it to Ansible Tower to deploy teh playbooks. Automated creation of S3 buckets using PowerShell and deploying to S3 buckets using Octopus deploy. 
 Extensive experience in working with Oracle WebLogic, JBOSS and Apache Tomcat application servers. Web application development using Agile methodology using Ruby on Rails, NOSQL databases such as MongoDB and Cassandra. 
 Installed, Congured & Managed Monitoring Tools such as Splunk, Nagios for Resource Monitoring/Network Monitoring/Log Trace Monitoring and Cloud Watch and ELK to monitor OS metrics, server health checks, le system usage etc. 
 Troubleshooting and monitoring of various proprietary Acxiom and 3rd party applications using Splunk and Cloud Watch in teh Amazon Web Services (AWS) environment. 
 Monitored servers, switches, and ports using Nagios Monitoring tool and assisted internal users of Splunk in designing and maintaining production quality dashboards. 
 Creating scripts in DSL Groovy which integrates with Jenkins for Automation to create seed jobs. Congured Webhooks for pushing teh commits from GIT to Jenkins and written Groovy scripts to automate Jenkins Pipeline and set up teh automate teh build in periodic time and set alerts to notify after teh build. 
 Analyse and evaluate existing architecture at Customer On premise Datacentres and Design, Congure and migrate complex network architectures to AWS Public Cloud. 
 Design of Cloud architectures for customers looking to migrate or develop newPaaS, IaaS, or hybrid solutions utilizing Microsoft Azure or Amazon Web Services (AWS). Worked with OpenShift platform in managing Docker containers and Kubernetes Clusters. 
 CreatedJenkinsCICD pipelines for continuous build & deployment and integratedJunitandSonarQubeplugins in Jenkins for automated testing and for Code quality check.
  Setup of monitoring tools like CloudStack and Amazon cloudwatch to monitor major metrices like Network packets, CPU utilization, Load Balancer Latency etc. 
 Installed, Create Virtual machine (KVM, VMware) and congured Red hat Enterprise Linux (RHEL5/6/7), Centos 5/6/7. Server racking, cabling and server built (kickstart). 
 Install and maintain security patches on teh operational and development system, which includes but is not limited to, Centos, Red Hat Linux, and Solaris 10.  



aws dataeng


Certied AWS Devops Engineer with over 8+ years of extensive IT experience, Expertise in DevOps and Cloud Engineering & UNIX, Linux Administration. 
 Exposed to all aspects of Software Development Life Cycle (SDLC) such as Analysis, Planning, Developing, Testing and implementing and Post - production analysis of the projects and methodologies such as Agile, SCRUM and waterfall. 
 Extensive experience in developing web pages using HTML/HTML5, XML, DHTML CSS/CSS3, SASS, LESS, JavaScript, React JS, Redux, Flex, Angular JS (1.X) jQuery, JSON, Node.js, Ajax, JQUERY Bootstrap. 
 Extensive experience in Amazon Web Services (AWS) Cloud services such as EC2, VPC, S3, IAM, EBS, RDS, ELB, VPC, Route53, Ops Works, DynamoDB, Autoscaling, CloudFront, CloudTrail, CloudWatch, CloudFormation, Elastic Beanstalk, AWS SNS, AWS SQS, AWS SES, AWS SWF & AWS Direct Connect. 
 Experience with designing, building, and operating solutions using virtualization using private hybrid/public cloud technologies. 
 Created Automation to create infrastructure for Kafka clusters dierent instances as per components in cluster using Terraform for creating multiple EC2 instances & attaching ephemeral or EBS volumes as per instance type in dierent availability zones & multiple regions in AWS 
 Implemented AWS X-Ray allows you to visually detect node and edge latency distribution directly from the service map Tools, like Splunk, Sumologic can be used for log analysis but when comes to distributed tracing with in the AWS, X-Ray will be provided much better features with service map, traces with in depth analysis with minimal conguration with not much maintenance. 
  Knowledge of High Availability (HA) and Disaster Recovery (DR) options in AWS. Hands on experience in Architecting Legacy Data Migration projects such as Teradata to AWS Redshift migration and from on-premises to AWS Cloud. 
 Designed, built, and deployed a multitude application utilizing almost all AWS stack (Including EC2, R53, S3, RDS, HSM Dynamo DB, SQS, IAM, and EMR), focusing on high-availability, fault tolerance, and autoscaling 
 Strong hands-on experience with Microservices like Spring IO, Spring Boot in deploying on various cloud Infrastructure like AWS. 
  Expertise in conguration and automation using Chef, Chef with Jenkins, Puppet, Ansible and Docker 
 Experience in conguring Docker Containers for Branching and deployed using Elastic Beanstalk. Experience in designing, installing and implementing Ansible conguration management system for managing Web applications, Environments conguration Files, Users, Mount points and Packages. 
Extensively worked on Jenkins and Hudson by installing, conguring and maintaining the purpose of Continuous Integration (CI) and for End-to-End automation for all build and deployments and in implementing CI/CD for database using Jenkins. 
 Congured SSH, SMTP, Build Tools, and Source Control repositories in Jenkins. Installed multiple plugins to Jenkins and Hands-on experience in deployment automation using Shell/Ruby scripting.
  Experience in setting up Baselines, Branching, Merging and Automation Processes using Shell, Ruby, and PowerShell scripts. 
 Extensive experience developing a green eld app large app using AWS Cognito, Lambda, API gateway, node backend, Postgres and React /Redux front end. 
  Worked on designing Poc's for implementing various ETL Process. 
 Experience in using build utilities like Maven, Ant and Gradle for building of jar, war, and ear les. Performed several types of testing like smoke, functional, system integration, white box, black box, gray box, positive, negative and regression testing 
  Worked in container-based technologies like Docker, Kubernetes and OpenShift. Expertise AWS Lambada function and API Gateway, to submit data via API Gateway that is accessible via Lambda function. 
  Managed conguration of Web App and Deploy to AWS cloud server through Chef. 
 Created instances in AWS as well as worked on migration to AWS from data center. 
 Developed AWS Cloud Formation templates and set up Auto scaling for EC2 instances. 
 Championed in cloud provisioning tools such as Terraform and CloudFormation. 
 Responsible for distributed applications across hybrid AWS and physical data centers. Wrote AWS Lambda functions in python for AWS's Lambda which invokes python scripts to perform various transformations and analytics on large data sets in EMR clusters. 
  Used Amazon EMR for map reduction jobs and test locally using Jenkins. Experience in setting up and managing ELK (Elastic Search, Log Stash & Kibana) Stack to collect, search and analyze logles across servers, log monitoring and created geo-mapping visualizations using Kibana in integration with AWS CloudWatch and Lambda. 
 Strong Experience in implementing Data warehouse solutions in Condential Redshift; Worked on various projects to migrate data from on premise databases to Condential Redshift, RDS and S3.  Experience in ETL techniques and Analysis and Reporting including hands on experience with the Reporting tools such as Cognos. 
  Experience on Cloud Databases and Data warehouses (SQL Azure and Condential Redshift/RDS). 
 Good knowledge on logical and physical Data Modeling using normalizing Techniques. Used principles of Normalization to improve the performance. Involved in ETL code using PL/SQL in order to meet requirements for Extract, transformation, cleansing and loading of data from source to target data structures. 
  Experience in automation and provisioning services on AWS  Experience building and optimizing AWS data pipelines, architectures and data sets. Good working experience on Hadoop tools related to Data warehousing like Hive, Pig and Hive involved in extracting the data from these tools on to the cluster using Sqoop. 
 PROFESSIONAL EXPERIENCE AWS DATA ENGINEER Condential Responsibilities: Experience in working with Teradata. And making the data to be batch processing using distributed computing. 
 Getting in touch with the Junior developers and keeping them updated with the present cutting-Edge technologies like Hadoop, Spark. 
  Linux (Red Hat 4/5/6), UNIX, Ubuntu, Windows 7,8,10 and iOS 
 Subversion (SVN), ClearCase, GitHub, Code Commit 
 BAMBOO, JENKINS 
 C, C++, PYTHON, JAVASCRIPT, SQL 
 React JS, Angular JS (1.x), Node JS 
 CODEDEPLOY, CODEPIPELINE 
 CHECKMARX, SONARQUBE, NEXUSIQ 
 ANT, MAVEN 
 JIRA, Rally, Remedy 
 SHELL, PYTHON, TYPESCRIPT 
 CloudFormation, Terraform 
 Apache Tomcat, JBOSS, Web sphere, Nginx 
 Oracle 7.x/8i/9i/10g/11g, Data warehouse, RDBMS 
 Ecosystems S3, Redshift Spectrum, Athena, Glue, AWS RedShift 
 SOAP, REST, JavaScript, CSS, Angular JS, HTML 
 Amazon Cloud Watch, Nagios, Splunk, nexus, 
 Chef, Ansible, PUPPET vSphere, VMware Workstation, Oracle Virtual Box, Hyper-V  Docker, Kubernetes, ECS 
 SELENIUM, Junit 
 FTP, HTTP, HTTPS, HTML, W3C, TCP, DNS, NIS, LDAP, SAMBA 
 NEXUS, GIT, ARTIFACTORY 
 LAMBDA, SNS, SQS, DYNAMODB, KINESIS, REDSHIFT, ANTHENA 
 CLOUDWATCH, CLOUDTRAIL, EC2, ECS, VPC, IAM, CONFIG, AWS X-RAY We help developers automatically build and deploy software into production multiple times a day safely while maintaining compliance in a highly regulated nancial industry. We use tools like Atlassian Bamboo, Bitbucket, Conuence, JIRA, Jenkins, Sonar type Nexus and Nexus IQ, SonarQube, Grunt, and Maven to get the job done. 

building and maintaining the infrastructure typically associated with developing. Implemented a 'serverless' architecture using API Gateway, Lambda, and Dynamo DB and deployed AWS Lambda code from Amazon S3 buckets. Created a Lambda Deployment function, and congured it to receive events from your S3 bucket
  Designed the data models to be used in data intensive AWS Lambda applications which are aimed to do complex analysis creating analytical reports for end-to-end traceability, lineage, denition of Key Business elements from Aurora. 
 Writing code that optimizes performance of AWS services used by application teams and provide Codelevel application security for clients (IAM roles, credentials, encryption, etc.) 
 Using SonarQube for continuous inspection of code quality and to perform automatic reviews of code to detect bugs. Managing AWS infrastructure and automation with CLI and API.
  Creating AWS Lambda functions using python for deployment management in AWS and designed, investigated and implemented public facing websites on Amazon Web Services and integrated it with other applications infrastructure. 
 Creating dierent AWS Lambda functions and API Gateways, to submit data via API Gateway that is accessible via Lambda function. 
 Responsible for Building Cloud Formation templates for SNS, SQS, Elastic search, Dynamo DB, Lambda, EC2, VPC, RDS, S3, IAM, Cloud Watch services implementation and integrated with Service Catalog. 
 Regular monitoring activities in Unix/Linux servers like Log verication, Server CPU usage, Memory check, Load check, Disk space verication, to ensure the application availability and performance by using cloud watch and AWS X-ray. implemented AWS X-Ray service inside Condential, it allows development teams to visually detect node and edge latency distribution directly from the service map Tools. 
 Design and Develop ETL Processes in AWS Glue to migrate Campaign data from external sources like S3, ORC/Parquet/Text Files into AWS Redshift. 
  Automate Datadog Dashboards with the stack through Terraform Scripts. 
 Developed le cleaners using Python libraries and made it clean. 
 Utilized Python Libraries like Boto3, NumPy for AWS. 
 Used Amazon EMR for map reduction jobs and test locally using Jenkins. 
 Data Extraction, aggregations and consolidation of Adobe data within AWS Glue using PySpark.  Create external tables with partitions using Hive, AWS Athena and Redshift. 
 Developed the PySprak code for AWS Glue jobs and for EMR. Good Understanding of other AWS services like S3, EC2 IAM, RDS Experience with Orchestration and Data Pipeline like AWS Step functions/Data Pipeline/Glue. 
 Provide a streamlined developer experience for delivering small serverless applications to solve business problems The Platform is a Lambda-based platform. It is composed of a pipeline and a runtime. 
Environment: AWS (EC2, S3, EBS, ELB, RDS, SNS, SQS, VPC,LAM Cloud formation, CloudWatch, ELK Stack), Bitbucket, Ansible, Python, Shell Scripting, PowerShell, GIT, Jira, JBOSS, Bamboo, Docker, Web Logic, Maven, Web sphere, Unix/Linux, AWS Xray,Dynamodb,Kinesis,CodeDeploy,CodePieline,CodeBuild,CodeCommit,Splunk,SonarQube. AWS CLOUD ENGINEER Condential Responsibilities: 
 Design, develop and implement next generation cloud infrastructure at Condential . Hands-on experience on working with AWS services like Lambda function, Athena, DynamoDB, Step functions, SNS, SQS, S3, IAM etc. 
 Developed internationalized multi-tenant SaaS solutions with responsive UI's using React or AngularJS, with NodeJS and CSS. 
 Creation of indexes, forwarder & indexer management, Splunk Field Extractor IFX, Search head Clustering, Indexer clustering, Splunk upgradation. 
  Install and congured Splunk clustered search head and Indexer, Deployment servers, Deployers.  Designing and implementing Splunk - based best practice solutions. Designed and Developed ETL jobs to extract data from Salesforce replica and load it in data mart in Redshift. 
 Responsible for Designing Logical and Physical data modelling for various data sources on Condential Redshift. 
  Experienced with event-driven and scheduled AWS Lambda functions to trigger various AWS resources. Integrated lambda with SQS and DynamoDB with step functions to iterate through list of messages and updated the status into DynamoDB table. 
 Worked in Server infrastructure development on AWS Cloud, extensive usage of Virtual Private Cloud (VPC), Cloud Formation, Lambda, Cloud Front, Cloud Watch, IAM, EBS, Security Group, Auto Scaling, Dynamo DB, Route53, and Cloud Trail. 
 Designing and building multi - terabyte, full end-to-end Data Warehouse infrastructure from the ground up on Condential Redshift for large scale data handling Millions of records every day. 
 Supported AWS Cloud environment with 2000 plus AWS instances congured Elastic IP and Elastic storage deployed in multiple Availability Zones for high availability. 
 Setup Log Analysis AWS Logs to Elastic Search and Kibana and Manage Searches, Dashboards, custom mapping and Automation of data. 
  Wrote python scripts to process semi-structured data in formats like JSON. 
 Used ETL component Sqoop to extract the data from MySQL and load data into HDFS. Good hands on experience with Python API by developing Kafka producer, consumer for writing Avro Schemes. 
 Managed Hadoop clusters using Cloudera. Extracted, Transformed, and Loaded (ETL) of data from multiple sources like Flat les, XML les, and Databases. 
  Used Cloud Watch for monitoring the server's (AWS EC2 Instances) CPU utilization and system memory. 
 Environment: AWS (EC2, S3, EBS, ELB, RDS, SNS, SQS, VPC, Redshift, Cloud formation, CloudWatch, ELK Stack), Jenkins, Ansible, Python, Shell Scripting, PowerShell, GIT, Microservice, Jira, JBOSS, Bamboo, Kubernetes, Docker, Web Logic, Maven, Web sphere, Unix/Linux, Nagios, Splunk, AWS Glue. AWS CLOUD ENGINEER Condential Responsibilities: Involved in the development of the UI using JSP, HTML5, CSS3, JavaScript, jQuery, AngularJS. Worked on JavaScript framework (Backbone.JS) to augment browser-based applications with MVC capability.  Managed the artifacts generated by Maven and Gradle in the Nexus repository and Converted Pom.xml into build. 
 Designed infrastructure for AWS application and workow using Terraform and had done implementation and continuous delivery of AWS infrastructure using Terraform. 
  Developed Python scripts to take backup of EBS volumes using AWS Lambda and Cloud Watch. 
 Developed and deployed stacks using AWS Cloud Formation Templates (CFT) and AWS Terraform. Used Jenkins and pipelines which helped us drive all Microservices builds out to the Docker registry and then deployed to Kubernetes. 
  Managed Docker orchestration and Docker containerization using Kubernetes 
 Used Kubernetes to orchestrate the deployment, scaling and management of Docker Containers. Automated builds using Maven and scheduled automated nightly builds using Jenkins. Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes.  Extensively worked on Hudson, Jenkins for continuous integration and for End to End automation for all build and deployments. 
  Resolved update, merge and password authentication issues in Bamboo and JIRA. Developed and maintained Python/Shell PowerShell scripts for build and release tasks and automating tasks. 
 Used Jenkins pipelines to drive all micro services builds out to the Docker registry and then deployed to Kubernetes, Created Pods and managed using Kubernetes. 
 Designed and implemented large scale business critical systems using Object oriented Design and Programming concepts using Python and Django. 
 Experienced in working Asynchronous Frameworks like NodeJS, Twisted and designing the automation framework using Python and Shell scripting. 
 Used Ansible Playbooks to setup and congure Continuous Delivery Pipeline and Tomcat servers. Deployed Micro Services, including provisioning AWS environments using Ansible Playbooks. automated various infrastructure activities like Continuous Deployment, Application Server setup, stack monitoring using Ansible playbooks and has Integrated Ansible with Jenkins.
   Prepared projects, dashboards, reports and questions for all JIRA related services. 
 POC to explore AWS Glue capabilities on Data cataloging and Data integration  Experience working in Agile Environment. 
 Environment: AWS (EC2, S3, EBS, ELB, RDS, SNS, SQS, VPC, Cloud formation, CloudWatch, ELK Stack), Bitbucket, Ansible, Python, Shell Scripting, PowerShell, GIT, Jira, JBOSS, Terraform, Redshift, Maven, Web sphere, Unix/Linux, AWS Xray,Dynamodb,Kinesis,CodeDeploy,CodePieline,CodeBuild,CodeCommit,Splunk,SonarQube. 
 Working in DevOps model to dene, develop, maintain and support products. Designed, Architecture and Built out Highly Available Puppet Masters (3.x) as the conguration management tool for the team, Jenkins for the Continuous Integration, and Sensu Monitoring tool (Open Source) to replace Nagios for monitoring the health of all the critical applications and server’s health. 
  Created custom Modules in Puppet to support the applications. 
 Worked on SparkSQL where the task is to fetch the NOTNULL data from two dierent tables and loads 
 Able to handle whole data using HWI using Cloudera Hadoop distribution UI. 
 Importing the complete data from RDBMS to HDFS cluster using Sqoop. 
 Well versed with testing the custom modules locally using Test Kitchen and Vagrant. Create develop and test environments of dierent applications by provisioning Kubernetes clusters on AWS using Docker, Ansible, and Terraform. 
  Integrated Jenkins to do auto build when code is pushed to GIT. Achieved the Continuous Integration and Continuous deployment (CI/CD) process using GIT, Jenkins, Puppet and Custom Repositories. 
  Worked on Jenkins builds using Ant and Maven. 
 Created slaves’ nodes for Jenkins to run the builds outside of Jenkins Master. 
 Experience working with conguring and managing RabbitMQ, and Redis. 
 Worked with and managed Big Data tools like Cassandra and Spark. Create develop and test environments of dierent applications by provisioning Kubernetes clusters on AWS using Docker, Ansible, and Terraform. 
  Write terraform scripts from scratch for building Dev, Staging, Prod and DR environments. 
 Congured servers to send the server and application data to Splunk. 
 Hands on experience with generating reports using Splunk. 
 Built and managed servers, rewall rules, storage and authentication to servers on OpenStack and AWS. 
 Well versed with AWS products such as EC2, S3, EBS, IAM, CloudWatch, CloudTrail, VPC, and Route53. Experience with working on scripting and automation in Bash and Perl to achieve the interconnectivity and integrate the DevOps tools. 
 Good knowledge on Ruby while working with creating custom modules in puppet to integrate the applications into Puppet. 
 Experience on working and conguring TCP/IP network on the newly built physical servers and bringing them onto the company’s network. servers on day-to-day system administration tasks, managing user keys, monitoring servers and working on the break-x issues. 
 Conguring the newly built physical servers through ILO, to connect to the network and deploy the required applications on them from puppet. 
Responsibilities: Set up an AWS Lambda function that runs every 15 minutes to check for repository changes and publishes a notication to an Amazon SNS topic. 
 Integrated services like Bitbucket AWS Code Pipeline and AWS Elastic Beanstalk to create a deployment pipeline.
  Created S3 buckets in the AWS environment to store les, sometimes which are required to serve static content for a web application. 
 Congured S3 buckets with various life cycle policies to archive the infrequently accessed data to storage classes based on requirement.
  Possess good knowledge in creating and launching EC2 instances using AMI’s of Linux, Ubuntu, RHEL, and Windows and wrote shell scripts to bootstrap instance. 
 Used IAM for creating roles, users, groups and implemented MFA to provide additional security to AWS account and its resources. AWS ECS and EKS for docker image storage and deployment. 
 Used Bamboo pipelines to drive all micro services builds out to the Docker registry and then deployed to Kubernetes, Created Pods and managed using Kubernetes. 
 Design an ELK system to monitor and search enterprise alerts. Installed, congured and managed the ELK Stack for Log management within EC2 / Elastic Load balancer for Elastic Search. 
 Create develop and test environments of dierent applications by provisioning Kubernetes clusters on AWS using Docker, Ansible, and Terraform. 
 Worked on deployment automation of all the micro services to pull image from the private Docker registry and deploy to Docker Swarm Cluster using Ansible. 
  Installed Ansible Registry for local upload and download of Docker images and even from Docker Hub. Create and maintain highly scalable and fault tolerant multi-tier AWS and Azure environments spanning across multiple availability zones using Terraform and CloudFormation. 
 Implemented domain name service (DNS) through route 53 to have highly available and scalable applications. 
  Maintained the monitoring and alerting of production and corporate servers using Cloud Watch service. 
 Worked on scalable distributed data system using Hadoop ecosystem in AWS EMR. 
 Migrated on premise database structure to Condential Redshift data warehouse. 
 Wrote various data normalization jobs for new data ingested into Redshift. Wrote scripts and indexing strategy for a migration to Condential Redshift from SQL Server and MySQL databases.
   The data is ingested into this application by using Hadoop technologies like PIG and HIVE.
  Worked on AWS Data Pipeline to congure data loads from S3 to into Redshift 
 Used JSON schema to dene table and column mapping from S3 data to Redshift On demand, secure EMR launcher with custom spark submit steps using S3 Event, SNS, KMS and Lambda function. 
 Environment: AWS (EC2, S3, EBS, ELB, RDS, SNS, SQS, VPC, Cloud formation, CloudWatch, ELK Stack), Bitbucket, Ansible, Python, Shell Scripting, PowerShell,ETL,AWS Glue, Jira, JBOSS, Bamboo, Docker, Web Logic, Maven, Web sphere, Unix/Linux, AWS Xray,Dynamodb,Kinesis,CodeDeploy,CodePieline,CodeBuild,CodeCommit,Splunk. DEVOPS MIDDLEWARE ENGINEER Condential Responsibilities: Created EBS volumes for storing application les for use with EC2 instances whenever they are mounted to them. 
  Experienced in creating RDS instances to serve data through servers for responding to requests.  Automated regular tasks using Python code and leveraged Lambda function wherever required. 
 Knowledge on Containerization Management and setup tool Kubernetes and ECS. Installed and congured Web Logic Application server 8.x/9.x/10.x/11x using graphic, console and silent mode and congured the Web Logic domain. 
  Determined and suggested hardware and software specic to the System and customized it. 
 Congured Node Manager for running managed servers. Installed and congured JBOSS 5.1/6.0, Apache Tomcat 6.0on dierent environments like Dev, Test, QA and Production. 
 Experience in designing, installing and implementing Ansible conguration management system for managing Web applications, Environments conguration Files, Users, Mount points and Packages. 
 Installed and congured Apache HTTP Server 2.0, Tomcat 7.0, IIS and Sun One Webservers in various environments Installed and congured plug - in for Apache HTTP server and Sun One Web server to proxy the request for Web Logic server. 
 Developed and maintained the continuous integration and deployment systems using Jenkins, ANT, Maven, Nexus, Ansible and Run deck.
   Experienced in creating Ansible playbooks, tasks, roles, templates. Completely automated the process of building OAuth, OpenID and SAML stacks with Ansible and Jenkins. 
 Deployment and troubleshooting of JAR, WAR, and EAR les on both stand alone and clustered environment in JBOSS 5.1/6.0, Web Logic 8.x/9.x/10.x and Apache tomcat 6.0. 
 Performed migration and Upgradation tasks like upgrading Web Logic server 9.x/10.x to Web Logic11.xand updating JDK's and installing service packs and patches for Web Logic Server. 
 Congure F5 load balancer with Web servers. Used F5 to capacity, performance and reliability of the applications. 
  Developed and run UNIX shell scripts and implemented auto deployment process. Solved server hang issues such as Deadlock, Application and Database level lock by taking thread dump and analyzed to get the root cause of the hang. 
ENVIRONMENT: Web Logic Application Server 8.x/9.x/10.x,11x JDK 1.4/1.51.6/1.7 , JBoss (5.1, 6.0), JRockit 8x, Apache 2. x, Tomcat 7.x/8.x, Sun One/ I Planet, IIS 6, Solaris 8/9, Red Hat LINUX, Windows 2007, F5 Load balancer, SiteMinder, ansible, Cassandra, Nagios, JMX, Oracle 8i/9i, JDBC, Subversion, EJB, JSP, Servlets, XML, MS Oce, Open SSL, Secure SSH. Performance monitoring and JVM Heap size and EJB monitoring using Wily Introscope and Load testing using Mercury Load Runner and JMeter with Thread and Heap analysis Using Samurai thread dump. 
  Used Subversion (SVN) to maintain present and historical source code versions and documentation. 
 TDA and Heap Analyzer for detecting blocking and locked threads. 
 Used HP OpenView for managing applications, network conditions and status across the platform.  Implemented standard backup procedures for both application and Web Logic server. Involved in assisting QA team in Load and Integration testing of J2EE applications on WebLogic Server and resolved complex issues. 
